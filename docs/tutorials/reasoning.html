<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Notes" href="../notes/index.html" /><link rel="prev" title="Retrosynthesis" href="retrosynthesis.html" />

    <meta name="generator" content="sphinx-3.1.2, furo 2020.12.09.beta21"/>
        <title>Knowledge Graph Reasoning - TorchDrug 0.1.0 documentation</title>
      <link rel="stylesheet" href="../_static/styles/furo.css?digest=a3f371badb8538d75df213ccffb17a4f6e8f3ac5">
    <link rel="stylesheet" href="../_static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="../_static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --font-stack: Helvetica, Arial, sans-serif, -apple-system;
  --font-stack--monospace: Courier, monospace;
  --color-brand-primary: #E5261F;
  --color-brand-content: #E5261F;
  --admonition-font-size: 1rem;
  --admonition-title-font-size: 1rem;
  --font-size--small--2: var(--font-size--small);
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --font-stack: Helvetica, Arial, sans-serif, -apple-system;
  --font-stack--monospace: Courier, monospace;
  --color-brand-primary: #E5261F;
  --color-brand-content: #E5261F;
  --admonition-font-size: 1rem;
  --admonition-title-font-size: 1rem;
  --font-size--small--2: var(--font-size--small);
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link id="pygments_dark_css" media="(prefers-color-scheme: dark)" rel="stylesheet" type="text/css" href="../_static/pygments_dark.css" />
    <link rel="stylesheet" href="../_static/styles/furo-extensions.css?digest=26485485040e7aaf717c13fd0188a5ad2c2deb60">
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script defer src="../_static/jquery.js"></script>
    <script defer src="../_static/underscore.js"></script>
    <script defer src="../_static/doctools.js"></script>
    <script defer src="../_static/language_data.js"></script>
    <script defer async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script defer src="../_static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>


<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">TorchDrug 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="https://torchdrug.ai">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.svg" alt="Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html">
  <input class="sidebar-search" placeholder="Search" name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quick Start</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../benchmark/index.html">Benchmark</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/property_prediction.html">Molecule Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/reasoning.html">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="property_prediction.html">Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notes/index.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label for="toctree-checkbox-3"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/graph.html">Graph Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/variadic.html">Batch Irregular Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/layer.html">Graph Neural Network Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/model.html">Customize Models &amp; Tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../paper.html">Papers Implemented</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label for="toctree-checkbox-4"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/core.html">torchdrug.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">torchdrug.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/datasets.html">torchdrug.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/transforms.html">torchdrug.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/metrics.html">torchdrug.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/layers.html">torchdrug.layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/models.html">torchdrug.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/tasks.html">torchdrug.tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html">torchdrug.utils</a></li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <div class="section" id="knowledge-graph-reasoning">
<h1>Knowledge Graph Reasoning<a class="headerlink" href="#knowledge-graph-reasoning" title="Permalink to this headline">¶</a></h1>
<p>In knowledge graphs, one important task is knowledge graph reasoning, which aims
at predicting missing (h,r,t)-links given existing (h,r,t)-links in a knowledge
graph. There are two kinds of well-known approaches to knowledge graph reasoning.
One is knowledge graph embedding and the other one is neural inductive logic
programming.</p>
<p>In this tutorial, we provide two examples to illustrate how to use TorchDrug
for knowledge graph reasoning.</p>
<div class="section" id="knowledge-graph-embedding">
<h2>Knowledge Graph Embedding<a class="headerlink" href="#knowledge-graph-embedding" title="Permalink to this headline">¶</a></h2>
<p>For knowledge graph reasoning, the first kind of popular method is the knowledge
graph embedding method. The basic idea is to learn an embedding vector for each
entity and relation in a knowledge graph based on existing (h,r,t)-links. Then
these embeddings are further used to predict missing links.</p>
<p>Next, we will introduce how to use knowledge graph embedding models for knowledge
graph reasoning.</p>
<div class="section" id="prepare-the-dataset">
<h3>Prepare the Dataset<a class="headerlink" href="#prepare-the-dataset" title="Permalink to this headline">¶</a></h3>
<p>We use the <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> dataset for illustration. <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> is constructed from
Freebase, and the dataset has 14,541 entities as well as 237 relations. For the
dataset, there is a standard split of training/validation/test sets. We can load
the dataset using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchdrug</span> <span class="kn">import</span> <span class="n">core</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">models</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FB15k237</span><span class="p">(</span><span class="s2">"~/kg-datasets/"</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="define-our-model">
<h3>Define our Model<a class="headerlink" href="#define-our-model" title="Permalink to this headline">¶</a></h3>
<p>Once we load the dataset, we are ready to build the model. Let’s take the RotatE
model as an example, we can use the following code for model construction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">RotatE</span><span class="p">(</span><span class="n">num_entity</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_entity</span><span class="p">,</span>
                      <span class="n">num_relation</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_relation</span><span class="p">,</span>
                      <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">max_score</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code> specifies the dimension of entity and relation embeddings.
<code class="docutils literal notranslate"><span class="pre">max_score</span></code> specifies the bias for inferring the plausibility of a (h,r,t)
triplet.</p>
<p>You may consider using a smaller embedding dimension for better efficiency.</p>
<p>Afterwards, we further need to define our task. For the knowledge graph embedding
task, we can simply use the following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">KnowledgeGraphEmbedding</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_negative</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                     <span class="n">adversarial_temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">num_negative</span></code> is the number of negative examples used for training, and
<code class="docutils literal notranslate"><span class="pre">adversarial_temperature</span></code> is the temperature for sampling negative examples.</p>
</div>
<div class="section" id="train-and-test">
<h3>Train and Test<a class="headerlink" href="#train-and-test" title="Permalink to this headline">¶</a></h3>
<p>Afterwards, we can now train and test our model. For model training, we need to
set up an optimizer and put everything together into an Engine instance with the
following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                     <span class="n">gpus</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
<span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_epoch</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we can reduce <code class="docutils literal notranslate"><span class="pre">num_epoch</span></code> for better efficiency.</p>
<p>Afterwards, we may further evaluate the model on the validation set using the
following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">solver</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="s2">"valid"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="neural-inductive-logic-programming">
<h2>Neural Inductive Logic Programming<a class="headerlink" href="#neural-inductive-logic-programming" title="Permalink to this headline">¶</a></h2>
<p>The other kind of popular method is neural inductive logic programming. The idea
of neural inductive logic programming is to learn logic rules from training data.
Once the logic rules are learned, they can be further used to predict missing links.</p>
<p>One popular method of neural inductive logic programming is NeuralLP. NeuralLP
considers all the chain-like rules (e.g., nationality = born_in + city_of) up to a
maximum length. Also, an attention mechanism is used to assign a scalar weight to
each logic rule. During training, the attention module is trained, so that we can
learn a proper weight for each rule. During testing, the logic rules and their
weights are used together to predict missing links.</p>
<p>Next, we will introduce how to deploy a NeuralLP model for knowledge graph reasoning.</p>
<div class="section" id="id3">
<h3>Prepare the Dataset<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>We start with loading the dataset. Similar to the tutorial of knowledge graph
embedding, the <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> dataset is used for illustration. We can load the
dataset by running the following commands:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchdrug</span> <span class="kn">import</span> <span class="n">core</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">models</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FB15k237</span><span class="p">(</span><span class="s2">"~/kg-datasets/"</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="id4">
<h3>Define our Model<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>Afterwards, we can now define the NeuralLP model with the following codes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchdrug.models.neurallp</span> <span class="kn">import</span> <span class="n">NeuralLogicProgramming</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">NeuralLogicProgramming</span><span class="p">(</span><span class="n">num_entity</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_entity</span><span class="p">,</span>
                               <span class="n">num_relation</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_relation</span><span class="p">,</span>
                               <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                               <span class="n">num_step</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                               <span class="n">num_lstm_layer</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code> is the dimension of entity and relation embeddings used in
NeuralLP. <code class="docutils literal notranslate"><span class="pre">num_step</span></code> is the maximum length of the chain-like rules (i.e., the
maximum number of relations in the body of a chain-like rule), which is typically
set to 3. <code class="docutils literal notranslate"><span class="pre">num_lstm_layer</span></code> is the number of LSTM layers used in NeuralLP.</p>
<p>Once we define our model, we are ready to define the task. As training NeuralLP
shares similar ideas to training knowledge graph embedding, we also use the following
knowledge graph embedding task:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">KnowledgeGraphEmbedding</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fact_ratio</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>
                                     <span class="n">num_negative</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                     <span class="n">sample_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The difference is that we need to specify the <code class="docutils literal notranslate"><span class="pre">fact_ratio</span></code>, which tells the code
how many facts are used to construct the background knowledge graph on which we
perform reasoning, and this hyperparameter is typically set to 0.75.</p>
</div>
<div class="section" id="id5">
<h3>Train and Test<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>With the model and task we have defined, we can not perform model training and
testing. Model training is similar to that of knowledge graph embedding models,
where we need to create an optimizer and feed every component into an Engine instance
by running the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0e-2</span><span class="p">)</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                     <span class="n">gpus</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">gpus</span></code> specifies the GPUs on which we would like to train the model. We may
specify multiple GPUs by using the form as above. For <code class="docutils literal notranslate"><span class="pre">num_epoch</span></code>, we can reduce
the value for efficiency purpose.</p>
<p>After model training, we can further use the following codes to evaluate the model
on the validation set</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">solver</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="s2">"valid"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../notes/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Notes</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="retrosynthesis.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Retrosynthesis</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2021, MilaGraph Group
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="../_sources/tutorials/reasoning.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Knowledge Graph Reasoning</a><ul>
<li><a class="reference internal" href="#knowledge-graph-embedding">Knowledge Graph Embedding</a><ul>
<li><a class="reference internal" href="#prepare-the-dataset">Prepare the Dataset</a></li>
<li><a class="reference internal" href="#define-our-model">Define our Model</a></li>
<li><a class="reference internal" href="#train-and-test">Train and Test</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural-inductive-logic-programming">Neural Inductive Logic Programming</a><ul>
<li><a class="reference internal" href="#id3">Prepare the Dataset</a></li>
<li><a class="reference internal" href="#id4">Define our Model</a></li>
<li><a class="reference internal" href="#id5">Train and Test</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
  </body>
</html>