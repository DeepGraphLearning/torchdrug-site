<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Notes" href="../notes/index.html" /><link rel="prev" title="Retrosynthesis" href="retrosynthesis.html" />

    <meta name="generator" content="sphinx-4.5.0, furo 2022.04.07"/>
        <title>Knowledge Graph Reasoning - TorchDrug 0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=68f4518137b9aefe99b631505a2064c3c42c9852" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --font-stack: Helvetica, Arial, sans-serif, -apple-system;
  --font-stack--monospace: Courier, monospace;
  --color-brand-primary: #E5261F;
  --color-brand-content: #E5261F;
  --admonition-font-size: 1rem;
  --admonition-title-font-size: 1rem;
  --font-size--small--2: var(--font-size--small);
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">TorchDrug 0.2.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="https://torchdrug.ai">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/torchdrug_logo_full.svg" alt="Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quick Start</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../benchmark/index.html">Benchmark</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/property_prediction.html">Molecule Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/reasoning.html">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="property_prediction.html">Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notes/index.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/graph.html">Graph Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/variadic.html">Batch Irregular Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/layer.html">Graph Neural Network Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/model.html">Customize Models &amp; Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/reference.html">Deal with References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../paper.html">Papers Implemented</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/core.html">torchdrug.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">torchdrug.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/datasets.html">torchdrug.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/transforms.html">torchdrug.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/metrics.html">torchdrug.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/layers.html">torchdrug.layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/models.html">torchdrug.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/tasks.html">torchdrug.tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html">torchdrug.utils</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="knowledge-graph-reasoning">
<h1>Knowledge Graph Reasoning<a class="headerlink" href="#knowledge-graph-reasoning" title="Permalink to this headline">#</a></h1>
<p>In knowledge graphs, one important task is knowledge graph reasoning, which aims
at predicting missing (h,r,t)-links given existing (h,r,t)-links in a knowledge
graph. There are two kinds of well-known approaches to knowledge graph reasoning.
One is knowledge graph embedding and the other one is neural inductive logic
programming.</p>
<p>In this tutorial, we provide two examples to illustrate how to use TorchDrug
for knowledge graph reasoning.</p>
<section id="knowledge-graph-embedding">
<h2>Knowledge Graph Embedding<a class="headerlink" href="#knowledge-graph-embedding" title="Permalink to this headline">#</a></h2>
<p>For knowledge graph reasoning, the first kind of popular method is the knowledge
graph embedding method. The basic idea is to learn an embedding vector for each
entity and relation in a knowledge graph based on existing (h,r,t)-links. Then
these embeddings are further used to predict missing links.</p>
<p>Next, we will introduce how to use knowledge graph embedding models for knowledge
graph reasoning.</p>
<section id="prepare-the-dataset">
<h3>Prepare the Dataset<a class="headerlink" href="#prepare-the-dataset" title="Permalink to this headline">#</a></h3>
<p>We use the <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> dataset for illustration. <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> is constructed from
Freebase, and the dataset has 14,541 entities as well as 237 relations. For the
dataset, there is a standard split of training/validation/test sets. We can load
the dataset using the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchdrug</span> <span class="kn">import</span> <span class="n">core</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">models</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FB15k237</span><span class="p">(</span><span class="s2">"~/kg-datasets/"</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="define-our-model">
<h3>Define our Model<a class="headerlink" href="#define-our-model" title="Permalink to this headline">#</a></h3>
<p>Once we load the dataset, we are ready to build the model. Letâ€™s take the RotatE
model as an example, we can use the following code for model construction.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">RotatE</span><span class="p">(</span><span class="n">num_entity</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_entity</span><span class="p">,</span>
                      <span class="n">num_relation</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_relation</span><span class="p">,</span>
                      <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">max_score</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code> specifies the dimension of entity and relation embeddings.
<code class="docutils literal notranslate"><span class="pre">max_score</span></code> specifies the bias for inferring the plausibility of a (h,r,t)
triplet.</p>
<p>You may consider using a smaller embedding dimension for better efficiency.</p>
<p>Afterwards, we further need to define our task. For the knowledge graph embedding
task, we can simply use the following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">KnowledgeGraphCompletion</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_negative</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                      <span class="n">adversarial_temperature</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">num_negative</span></code> is the number of negative examples used for training, and
<code class="docutils literal notranslate"><span class="pre">adversarial_temperature</span></code> is the temperature for sampling negative examples.</p>
</section>
<section id="train-and-test">
<h3>Train and Test<a class="headerlink" href="#train-and-test" title="Permalink to this headline">#</a></h3>
<p>Afterwards, we can now train and test our model. For model training, we need to
set up an optimizer and put everything together into an Engine instance with the
following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">2e-5</span><span class="p">)</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                     <span class="n">gpus</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>
<span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_epoch</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, we can reduce <code class="docutils literal notranslate"><span class="pre">num_epoch</span></code> for better efficiency.</p>
<p>Afterwards, we may further evaluate the model on the validation set using the
following code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">solver</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="s2">"valid"</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="neural-inductive-logic-programming">
<h2>Neural Inductive Logic Programming<a class="headerlink" href="#neural-inductive-logic-programming" title="Permalink to this headline">#</a></h2>
<p>The other kind of popular method is neural inductive logic programming. The idea
of neural inductive logic programming is to learn logic rules from training data.
Once the logic rules are learned, they can be further used to predict missing links.</p>
<p>One popular method of neural inductive logic programming is NeuralLP. NeuralLP
considers all the chain-like rules (e.g., nationality = born_in + city_of) up to a
maximum length. Also, an attention mechanism is used to assign a scalar weight to
each logic rule. During training, the attention module is trained, so that we can
learn a proper weight for each rule. During testing, the logic rules and their
weights are used together to predict missing links.</p>
<p>Next, we will introduce how to deploy a NeuralLP model for knowledge graph reasoning.</p>
<section id="id3">
<h3>Prepare the Dataset<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p>We start with loading the dataset. Similar to the tutorial of knowledge graph
embedding, the <a class="reference external" href="https://www.aclweb.org/anthology/W15-4007">FB15k-237</a> dataset is used for illustration. We can load the
dataset by running the following commands:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchdrug</span> <span class="kn">import</span> <span class="n">core</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">models</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FB15k237</span><span class="p">(</span><span class="s2">"~/kg-datasets/"</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="id4">
<h3>Define our Model<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h3>
<p>Afterwards, we can now define the NeuralLP model with the following codes:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">NeuralLP</span><span class="p">(</span><span class="n">num_relation</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">num_relation</span><span class="p">,</span>
                        <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
                        <span class="n">num_step</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                        <span class="n">num_lstm_layer</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">hidden_dim</span></code> is the dimension of entity and relation embeddings used in
NeuralLP. <code class="docutils literal notranslate"><span class="pre">num_step</span></code> is the maximum length of the chain-like rules (i.e., the
maximum number of relations in the body of a chain-like rule), which is typically
set to 3. <code class="docutils literal notranslate"><span class="pre">num_lstm_layer</span></code> is the number of LSTM layers used in NeuralLP.</p>
<p>Once we define our model, we are ready to define the task. As training NeuralLP
shares similar ideas to training knowledge graph embedding, we also use the following
knowledge graph embedding task:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">task</span> <span class="o">=</span> <span class="n">tasks</span><span class="o">.</span><span class="n">KnowledgeGraphCompletion</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">fact_ratio</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span>
                                      <span class="n">num_negative</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                      <span class="n">sample_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>The difference is that we need to specify the <code class="docutils literal notranslate"><span class="pre">fact_ratio</span></code>, which tells the code
how many facts are used to construct the background knowledge graph on which we
perform reasoning, and this hyperparameter is typically set to 0.75.</p>
</section>
<section id="id5">
<h3>Train and Test<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h3>
<p>With the model and task we have defined, we can not perform model training and
testing. Model training is similar to that of knowledge graph embedding models,
where we need to create an optimizer and feed every component into an Engine instance
by running the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1.0e-3</span><span class="p">)</span>
<span class="n">solver</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Engine</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                     <span class="n">gpus</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="n">solver</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">num_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">gpus</span></code> specifies the GPUs on which we would like to train the model. We may
specify multiple GPUs by using the form as above. For <code class="docutils literal notranslate"><span class="pre">num_epoch</span></code>, we can reduce
the value for efficiency purpose.</p>
<p>After model training, we can further use the following codes to evaluate the model
on the validation set</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">solver</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="s2">"valid"</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../notes/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Notes</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="retrosynthesis.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Retrosynthesis</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2021, MilaGraph Group
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Knowledge Graph Reasoning</a><ul>
<li><a class="reference internal" href="#knowledge-graph-embedding">Knowledge Graph Embedding</a><ul>
<li><a class="reference internal" href="#prepare-the-dataset">Prepare the Dataset</a></li>
<li><a class="reference internal" href="#define-our-model">Define our Model</a></li>
<li><a class="reference internal" href="#train-and-test">Train and Test</a></li>
</ul>
</li>
<li><a class="reference internal" href="#neural-inductive-logic-programming">Neural Inductive Logic Programming</a><ul>
<li><a class="reference internal" href="#id3">Prepare the Dataset</a></li>
<li><a class="reference internal" href="#id4">Define our Model</a></li>
<li><a class="reference internal" href="#id5">Train and Test</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    </body>
</html>