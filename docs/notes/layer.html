<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/><link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Customize Models &amp; Tasks" href="model.html" /><link rel="prev" title="Batch Irregular Structures" href="variadic.html" />

    <meta name="generator" content="sphinx-3.1.2, furo 2020.12.09.beta21"/>
        <title>Graph Neural Network Layers - TorchDrug 0.1.1 documentation</title>
      <link rel="stylesheet" href="../_static/styles/furo.css?digest=a3f371badb8538d75df213ccffb17a4f6e8f3ac5">
    <link rel="stylesheet" href="../_static/pygments.css">
    <link media="(prefers-color-scheme: dark)" rel="stylesheet" href="../_static/pygments_dark.css">
    


<style>
  :root {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --font-stack: Helvetica, Arial, sans-serif, -apple-system;
  --font-stack--monospace: Courier, monospace;
  --color-brand-primary: #E5261F;
  --color-brand-content: #E5261F;
  --admonition-font-size: 1rem;
  --admonition-title-font-size: 1rem;
  --font-size--small--2: var(--font-size--small);
  
  }
  @media (prefers-color-scheme: dark) {
    :root {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }

  /* For allowing end-user-specific overrides */
  .override-light {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --font-stack: Helvetica, Arial, sans-serif, -apple-system;
  --font-stack--monospace: Courier, monospace;
  --color-brand-primary: #E5261F;
  --color-brand-content: #E5261F;
  --admonition-font-size: 1rem;
  --admonition-title-font-size: 1rem;
  --font-size--small--2: var(--font-size--small);
  
  }
  .override-dark {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
</style><link id="pygments_dark_css" media="(prefers-color-scheme: dark)" rel="stylesheet" type="text/css" href="../_static/pygments_dark.css" />
    <link rel="stylesheet" href="../_static/styles/furo-extensions.css?digest=26485485040e7aaf717c13fd0188a5ad2c2deb60">
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script defer src="../_static/jquery.js"></script>
    <script defer src="../_static/underscore.js"></script>
    <script defer src="../_static/doctools.js"></script>
    <script defer src="../_static/language_data.js"></script>
    <script defer async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script defer src="../_static/scripts/main.js?digest=e931d09b2a40c1bb82b542effe772014573baf67"></script></head>
  <body dir="">
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke-width="1.5" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z"/>
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none"
      stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"
      class="feather feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation"></label>
<label class="overlay toc-overlay" for="__toc"></label>


<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">TorchDrug 0.1.1 documentation</div></a>
    </div>
    <div class="header-right">
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="https://torchdrug.ai">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.svg" alt="Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html">
  <input class="sidebar-search" placeholder="Search" name="q">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">Quick Start</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../benchmark/index.html">Benchmark</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label for="toctree-checkbox-1"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/property_prediction.html">Molecule Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../benchmark/reasoning.html">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials/index.html">Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label for="toctree-checkbox-2"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/property_prediction.html">Property Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/pretrain.html">Pretrained Molecular Representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/generation.html">Molecule Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/retrosynthesis.html">Retrosynthesis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/reasoning.html">Knowledge Graph Reasoning</a></li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Notes</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label for="toctree-checkbox-3"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="graph.html">Graph Data Structures</a></li>
<li class="toctree-l2"><a class="reference internal" href="variadic.html">Batch Irregular Structures</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Graph Neural Network Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="model.html">Customize Models &amp; Tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../paper.html">Papers Implemented</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/index.html">Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label for="toctree-checkbox-4"><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../api/core.html">torchdrug.core</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/data.html">torchdrug.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/datasets.html">torchdrug.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/transforms.html">torchdrug.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/metrics.html">torchdrug.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/layers.html">torchdrug.layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/models.html">torchdrug.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/tasks.html">torchdrug.tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api/utils.html">torchdrug.utils</a></li>
</ul>
</li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <main class="main">
    <div class="content">
      <article role="main">
        <label class="toc-overlay-icon toc-content-icon" for="__toc">
          <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
        </label>
        <div class="section" id="graph-neural-network-layers">
<h1>Graph Neural Network Layers<a class="headerlink" href="#graph-neural-network-layers" title="Permalink to this headline">¶</a></h1>
<p>Modern graph neural networks encode graph structures with message passing layers
and readout layers. In some cases, graph-to-node broadcast may also be needed. All
these operations can be easily implemented with TorchDrug.</p>
<div class="table-wrapper"><table class="docutils align-default">
<colgroup>
<col style="width: 33%"/>
<col style="width: 32%"/>
<col style="width: 35%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><img alt="fig. message passing" src="../_images/message_passing.png"/>
Message passing</p></td>
<td><p><img alt="fig. readout" src="../_images/readout.png"/>
Node-to-graph readout</p></td>
<td><p><img alt="fig. broadcast" src="../_images/broadcast.png"/>
Graph-to-node broadcast</p></td>
</tr>
</tbody>
</table></div>
<div class="section" id="message-passing-layers">
<h2>Message Passing Layers<a class="headerlink" href="#message-passing-layers" title="Permalink to this headline">¶</a></h2>
<p>A message passing layer can be described as 3 steps, a message generation step, an
aggregation step and a combination step. The <span class="math notranslate nohighlight">\(t\)</span>-th message passing layer
performs the following computation</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\begin{split}m_{i,j}^{(t+1)} &amp;= Message^{(t)}(h_i^{(t)}, h_j^{(t)}) \\
u_i^{(t+1)} &amp;= Aggregate^{(t)}(\{m_{i,j}^{(t+1)} \mid j \in N(i)\}) \\
h_i^{(t+1)} &amp;= Combine^{(t)}(h_i^{(t)}, u_i^{(t+1)})\end{split}\]</div></div>
<p>where <span class="math notranslate nohighlight">\(h_i^{(t)}\)</span> denotes node representations, <span class="math notranslate nohighlight">\(m_{i,j}^{(t)}\)</span> denotes
messages from node <span class="math notranslate nohighlight">\(j\)</span> to node <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(u_i^{(t)}\)</span> is the
aggregated messages, i.e., updates.</p>
<p>In TorchDrug, these steps are abstracted as three methods, namely
<code class="xref py py-meth docutils literal notranslate"><span class="pre">message(graph,</span> <span class="pre">input)</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">aggregate(graph,</span> <span class="pre">message)</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">combine(input,</span> <span class="pre">update)</span></code>.</p>
<p>Here we show an example of a custom message passing for <a class="reference external" href="https://en.wikipedia.org/wiki/PageRank">PageRank</a> algorithm.
Representing the PageRank value as <span class="math notranslate nohighlight">\(h_i^{(t)}\)</span>, one PageRank iteration is
equivalent to the following functions.</p>
<div class="math-wrapper"><div class="math notranslate nohighlight">
\[\begin{split}Message^{(t)}(h_i^{(t)}, h_j^{(t)}) &amp;= \frac{h_j^{(t)}}{degree\_in_j} \\
Aggregate^{(t)}(\{m_{i,j} \mid j \in N(i)\}) &amp;= \sum_{j \in N(i)} m_{i,j} \\
Combine^{(t)}(h_i^{(t)}, u_i^{(t+1)}) &amp;= u_i^{(t+1)}\end{split}\]</div></div>
<p>We use the convention that <span class="math notranslate nohighlight">\(degree\_in_j\)</span> represents the degree of node
<span class="math notranslate nohighlight">\(j\)</span> as the source node of any edge. The corresponding implementation is</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_add</span>
<span class="kn">from</span> <span class="nn">torchdrug</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="k">class</span> <span class="nc">PageRankIteration</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">MessagePassingBase</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">node_in</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">edge_list</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">message</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">node_in</span><span class="p">]</span> <span class="o">/</span> <span class="n">graph</span><span class="o">.</span><span class="n">degree_in</span><span class="p">[</span><span class="n">node_in</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">message</span>

    <span class="k">def</span> <span class="nf">aggregate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">message</span><span class="p">):</span>
        <span class="n">node_out</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">edge_list</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
        <span class="n">update</span> <span class="o">=</span> <span class="n">scatter_add</span><span class="p">(</span><span class="n">node_out</span><span class="p">,</span> <span class="n">message</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">num_node</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">update</span>

    <span class="k">def</span> <span class="nf">combine</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">update</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">update</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Let’s elaborate the functions one by one. In <code class="xref py py-meth docutils literal notranslate"><span class="pre">message()</span></code>, we pick the source
nodes of all edges, and compute the messages by dividing the source nodes’ hidden
states with their source degrees.</p>
<p>In <code class="xref py py-meth docutils literal notranslate"><span class="pre">aggregate()</span></code>, we collect the messages by their target nodes. This is
implemented by <code class="xref py py-func docutils literal notranslate"><span class="pre">scatter_add()</span></code> operation from <a class="reference external" href="https://pytorch-scatter.readthedocs.io">PyTorch Scatter</a>. We specify
<code class="xref py py-attr docutils literal notranslate"><span class="pre">dim_size</span></code> to be <code class="docutils literal notranslate"><span class="pre">graph.num_node</span></code>, since there might be isolated nodes in
the graph and <code class="xref py py-func docutils literal notranslate"><span class="pre">scatter_add()</span></code> cannot figure it out from <code class="docutils literal notranslate"><span class="pre">node_in</span></code>.</p>
<p>The <code class="xref py py-meth docutils literal notranslate"><span class="pre">combine()</span></code> function trivially returns node updates as new node hidden
states.</p>
</div>
<div class="section" id="readout-and-broadcast-layers">
<h2>Readout and Broadcast Layers<a class="headerlink" href="#readout-and-broadcast-layers" title="Permalink to this headline">¶</a></h2>
<p>A readout layer collects all node representations in a graph to form a graph
representation. Reversely, a broadcast layer sends the graph representation to every
node in the graph. For a batch of graphs, these operations can be viewed as message
passing on a bipartite graph – one side are original nodes, and the other side are
“graph” nodes.</p>
<p>TorchDrug provides effcient primitives to support this kind of message passing.
Specifically, <a class="reference internal" href="../api/data.html#torchdrug.data.PackedGraph.node2graph" title="torchdrug.data.PackedGraph.node2graph"><code class="xref py py-attr docutils literal notranslate"><span class="pre">node2graph</span></code></a> maps
node IDs to graph IDs, and <a class="reference internal" href="../api/data.html#torchdrug.data.PackedGraph.edge2graph" title="torchdrug.data.PackedGraph.edge2graph"><code class="xref py py-attr docutils literal notranslate"><span class="pre">edge2graph</span></code></a>
maps edge IDs to graph IDs.</p>
<p>In this example, we will use the above primitives to compute the variance of node
representations as a graph representation. First, we readout the mean of node
representations. Second, we broadcast the mean representation to each node to compute
the difference. Finally, we readout the mean of the squared difference as the variance.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch_scatter</span> <span class="kn">import</span> <span class="n">scatter_mean</span>

<span class="k">class</span> <span class="nc">Variance</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">node2graph</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="nb">input</span> <span class="o">-</span> <span class="n">mean</span><span class="p">[</span><span class="n">graph</span><span class="o">.</span><span class="n">node2graph</span><span class="p">]</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">scatter_mean</span><span class="p">(</span><span class="n">diff</span> <span class="o">*</span> <span class="n">diff</span><span class="p">,</span> <span class="n">graph</span><span class="o">.</span><span class="n">node2graph</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">var</span>
</pre></div>
</div>
<p>Notice that <a class="reference internal" href="../api/data.html#torchdrug.data.PackedGraph.node2graph" title="torchdrug.data.PackedGraph.node2graph"><code class="xref py py-attr docutils literal notranslate"><span class="pre">node2graph</span></code></a> is used
for both readout and broadcast. When used in a scatter function, it serves as
readout. When used in a conventional indexing, it is equivalent to broadcast.</p>
</div>
</div>

      </article>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="model.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Customize Models &amp; Tasks</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="variadic.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Batch Irregular Structures</div>
                
              </div>
            </a>
        </div>

        <div class="related-information">
              Copyright &#169; 2021, MilaGraph Group
            |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>.
            |
            <a class="muted-link" href="../_sources/notes/layer.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Graph Neural Network Layers</a><ul>
<li><a class="reference internal" href="#message-passing-layers">Message Passing Layers</a></li>
<li><a class="reference internal" href="#readout-and-broadcast-layers">Readout and Broadcast Layers</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </main>
</div>
  </body>
</html>